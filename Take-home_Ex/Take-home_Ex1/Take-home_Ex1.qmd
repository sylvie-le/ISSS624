---
title: "Take-home Exercise 1: How Functional are the Water Points in Nigeria?"
editor: visual
execute: 
  warning: false
  message: false
format: 
  html:
    code-fold: true
    code-summary: "Show code"
---

## Overview

### Social Context

Water is a critical asset of all communities and nations. It is the core neccessity to sustain the life of both humans and livestock. Lack of access to potable water can lead to serious health hazards and even conflicts between communities and states. According to a 2022 report by World Bank, about 70 million Nigerians do not have access to drinkable water. Access to piped water has decreased from 39% in 1990 to only 11% in 2021. This phenomenon contributes to a surge in violence in Nigeria when communities Fulani herders ad farmers fight over water supplies.

Why is there a water crisis in Nigeria? To gain a perspective on the answer, we will examine the quality and distribution of water supply points in Nigeria.

### Objective

The objective of this exercise is to apply appropriate global and local measures of spatial association techniques to reveals the spatial patterns of non-functional water points in Nigeria.

## Setup

### Data

#### Aspatial Data

The aspatial data of water points quality, status and other relevant information is taken from [WPdx Global Data Repositories - WPdx+ version](https://data.waterpointdata.org/dataset/Water-Point-Data-Exchange-Plus-WPdx-/eqje-vguj/data). The data set is downloaded in Shapefile format.

#### Geospatial Data

The geospatial data of Nigeria administrative regions is downloaded from [Geoboundaries](https://www.geoboundaries.org/index.html#getdata). The data level of ADM2, published in 2020, will be used.

### R Packages Used

-   **sf**: used for importing, managing, and processing geospatial data

-   **tidyverse**: a collection of packages for data science tasks. It contains the sub-packages dplyr, ggplot2, forcats, tibble, readr, stringr, tidyr, purrr

-   **tmap**: used for creating thematic maps, such as choropleth and bubble maps

-   **spdep**: used for calculating spatial dependence - weighting schemes and statistics

-   **funModeling**: used for EDA and data preparation

We load the packages into our working environment using the code below.

```{r}
pacman::p_load(sf, tidyverse, tmap, spdep, funModeling)
```

## Importing Data

### Importing Nigeria water point geospatial data

The data from WPdx Global Data Repositories comes in four files in dbf, prj, shp, shx formats. The files are renamed into `geo_export` for a more convenient reference.

Using `st_read()` from the **sf** package, we import the aspatial data into our working environment. The data is imported as a simple feature data table.

```{r}
#| eval: false
wp <- st_read(dsn = "data", layer = "geo_export")
```

### Importing Nigeria ADM2 aspatial data

The data from Geoboundaries comes in six files in dbf, geojson, prj, shp, shx, topojson formats. The files are renamed to `NGA-ADM2` for easier reference. To import these files as a simple feature data table, we also use `st_read().`

```{r}
#| eval: false
nga <- st_read(dsn = "data", layer = "NGA-ADM2")
```

## Exploratory Data Analysis and Data Wrangling

The goals of this step include:

-   Examine the data structure and format, ensure consistent format between geospatial and aspatial data.

-   Study the content of the data tables and filter out data that are not related to water points in Nigeria.

-   Explore data type and data validity relating to the functionality of water points in Nigeria, transform the data where necessary.

### `wp` geospatial data

#### Checking the CRS of geospatial data

First, we use `st_geometry()` to check the geometry list column of `wp`. There are 406,566 observations under the WGS84 coordinate reference system (CRS). Let's take notes that the geometry type is `point` ðŸ”‘

```{r}
#| eval: false
st_geometry(wp)
```

Since the shapefile is in WGS84 CRS, we will assign `crs = 4326` to `wp`. 4326 is the code of WGS84 in EPSG code. The task is conducted using `st_set_crs()`.

```{r}
#| eval: false
wp <- st_set_crs(wp, 4326)
```

#### Filtering relevant information

Next, we will examine the attributes in the data table using `glimpse()` from **dplyr**.

```{r}
#| eval: false
glimpse(wp)
```

We notice that in the `clean_coun` column, there are many countries name such as Malawi, Ghana, Sierra Leone, etc. This means that the `wp` data set contains the information of other countries besides Nigeria. `filter()` of the package **dplyr** is used to get the data that only belongs to Nigeria.

```{r}
#| eval: false
wp <- wp %>% filter(clean_coun == "Nigeria")
```

Now we will examine the filtered `wp` data set using `head()` of Base R. The function reveals that `wp` now only contains Nigeria-relevant data.

```{r}
#| eval: false
head(wp, n = 5)
```

Now we will write the filtered data table into a new `rds` file named `wp_nga` using the `write_rds()` function from the **sf** package.

```{r}
#| eval: false
write_rds(wp, "data/wp_nga.rds")
```

From this point on, we will work on the `wp_nga` file.

#### Exploring the water point status data

From the result of the code above, we notice that column `status_cle` has NA values. Since our goal is to examine the functionality of the water points, the data in `status_cle` should be transformed to remove the NA values. One way to do it is to recode the NA values to "Unknown". `replace_na()` from the **tidyr** package is used to do the mentioned task.

To preserve the existing variables while adding new ones, `mutate()` from the **dplyr** package is used.

All changes are written into the `wp_nga` file using `read_rds()`.

```{r}
#| eval: false
wp_nga <- read_rds("data/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

Let's look at the distribution of `status_cle`. We will use `freq()` from the **funModeling** package for this task.

```{r}
#| eval: false
freq(data=wp_nga, 
     input = 'status_cle')
```

We can see that there are two variables that carry the same meaning: *Non-Functional due to dry season* and *Non functional due to dry season*. We will use `replace()` from **dplyr** to do this task.

```{r}
#| eval: false
wp_nga <- read_rds("data/wp_nga.rds") %>%
  mutate(status_cle = replace(status_cle, status_cle == "Non functional due to dry season", "Non-Functional due to dry season")) %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

Let's re-examine the distribution of `status_cle`.

```{r}
#| eval: false
freq(data=wp_nga, 
     input = 'status_cle')
```

#### Extracting non-functional water point data

Non-functional water points are defined as those which are not functional or abandoned. Using `filter()` from the dplyr package, we will save the non-functional water point data into a simple feature data table named `wpt_nonfunctional`.

```{r}
#| eval: false
wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non-Functional due to dry season"))
```

Now we can inspect the distribution of non-functional water points by type using `freq()`.

```{r}
#| eval: false
freq(data = wpt_nonfunctional, input = "status_cle")
```

### `nga` aspatial data

#### Checking the CRS of aspatial data

We will check the CRS of `nga` using `st_geometry()`.

```{r}
#| eval: false
st_geometry(nga)
```

As the CRS of `nga` is WGS84, we will assign `crs = 4326` using `st_set_crs()`.

```{r}
#| eval: false
nga <- st_set_crs(nga, 4326)
```

Next, we plot the geometry using `plot()` of Base R. As our data is the regions of Nigeria by administrative division management level 2, the map below depicts the [774 Local Government Areas of Nigeria](https://en.wikipedia.org/wiki/Local_government_areas_of_Nigeria).

From the map, it is noticeable that the size of government areas varies significantly. Let's keep this in mind for further analysis ðŸ’ª

```{r}
#| eval: false
plot(st_geometry(nga))
```

### Performing Point-in-Polygon Count

Because the geometry type of our geospatial data is `point`, we need to compute the number of points inside each polygon. The functions below will be used for that task.

-   `mutate()`: preserves the existing variables while adding new variables, from **dplyr** package

-   `st_intersects()`: spatial intersect predicate for stars and sfc object, from **stars** package, a sub-package of **tmap**.

-   `lengths()`: get the length of each element of a list or atomic vector as an integer or numeric vector, from Base R.

After the aggregation, the output will in in polygon geometry shape.

```{r}
#| eval: false
nga_wp <- nga %>%
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_nga))) %>% 
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional)))
```

### Saving the analytical data table

Before saving the data table, we will compute the percentage of non-functional water points over the total number of water points in Nigeria.

```{r}
#| eval: false
nga_wp <- nga_wp %>% 
  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`)
```

Now, we will save the sf data table `nga_wp` into a new rds file.

```{r}
#| eval: false
write_rds(nga_wp, "data/nga_wp.rds")
```

## Visualizing the Data

First, let's reload the `nga_wp.rds` file into our working environment.

```{r}
nga_wp <- read_rds("data/nga_wp.rds")
```

### Displaying non-functional water points with choropleth map

To create the plots, we will use the `tm_shape()` and `tm_fill()` functions from **tmap** package. In addition, `tm_borders()` and `tm_layout()` will be used to customize the style of the map. Below are the functionality of the functions.

-   `tm_shape`: creates a tmap element that specifies the spatial data object.

-   `tm_fill`: creates a tmap element that draws the polygons.

-   `tm_borders`: creates a tmap element that defines the border of the polygons.

-   `tm_layout`: specifies the map layout

```{r}
wp_pretty <- tm_shape(nga_wp) + 
  tm_fill("wpt non-functional",
          title = "Water Point Count") +
  tm_layout(main.title = "Pretty Classification",
            main.title.position = "center",
            main.title.size = 2,
            legend.height = 0.25,
            legend.width = 0.3,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)

wp_quantile <- tm_shape(nga_wp) + 
  tm_fill("wpt non-functional",
          title = "Water Point Count",
          style = "quantile") +
  tm_layout(main.title = "Quantile Classification",
            main.title.position = "center",
            main.title.size = 2,
            legend.height = 0.25,
            legend.width = 0.3,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)

wp_equal <- tm_shape(nga_wp) + 
  tm_fill("wpt non-functional",
          title = "Water Point Count",
          style = "equal") +
  tm_layout(main.title = "Equal Classification",
            main.title.position = "center",
            main.title.size = 2,
            legend.height = 0.25,
            legend.width = 0.3,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)

wp_jenks <- tm_shape(nga_wp) + 
  tm_fill("wpt non-functional",
          title = "Water Point Count",
          style = "jenks") +
  tm_layout(main.title = "Jenks Classification",
            main.title.position = "center",
            main.title.size = 2,
            legend.height = 0.25,
            legend.width = 0.3,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```

```{r}
wp_equal
wp_pretty
wp_jenks
wp_quantile
```

From the maps above, we can see that different interval classification produces different map views.

`pretty` and `equal` methods divide the values into groups of equally-spaced values, so they can smooth out the distribution of non-functional water points.

The `Jenks` method produces well-balanced intervals. By definition, the Jenks method defines intervals so that they have the smallest in-class variance. This makes the Jenks method more suitable for high-variance data sets like `nga_wp`.

The `quantile` method produces a rather dire situation with a large area of land having the highest numbers of non-functional water points. However, the range of the highest quantile is relatively huge comparing to other quantiles, suggesting high variance data. We can say that the quantile method exaggerates the disfunctionality of water points in Nigeria due to outliers.

#### Displaying data distribution with histogram

To confirm the distribution of the data, we will use a histogram. From the histogram, it is clear that the data is highly skewed toward the right.

```{r}
hist(nga_wp$`wpt non-functional`, xlab = "Non-functional Water Point Count",
     main = "Histogram of non-functional water points")
```

## Global Spatial Autocorrelation

Based on the maps above, we see that there are some areas with a higher number of non-functional water points than others. Is there a pattern for the distribution of the non-functional water points or do they just occur randomly? To answer that question, we will explore the global spatial autocorrelation of non-functional water points in Nigeria.

### Computing Spatial Weights

Let's consider four spatial weight methods.

-   **Polygon Contiguity**: this method defines the neighbor based on contiguity and is effective when the polygons are similar in size and distribution, and when spatial relationships are a function of polygon proximity. In this case, the size of the government areas of Nigeria have significantly varying sizes. Therefore, polygon contiguity is not a good fit.

-   **Fixed Distance**: this method is effective for polygon data with large variation in polygon size (very large polygons at the edge of the study area, and very small polygons at the center of the study areas). On the map, we can see that Nigeria has very small government areas in the south, while bigger areas are scattered in the rest of the country, together with smaller areas in between. Therefore, the Fixed Distance method is not a good fit.

-   **Inverse Distance:** this method is appropriate for with continuous data or to model the process where the closer the features are, the more likely they are going to interact/affect the other. The downside of this approach is that it considers every feature is potentially a neighbor of every other feature. Therefore, the method is computationally costly. Since our data set has up to 774 observations, this method is not appropriate considering the capability of our personal computer.

-   **Adaptive Distance (K Nearest Neighbor):** this method is effective when the values associate with the features are skewed. Because our data is skewed to the right, this method is a good fit.

#### Converting data into projected coordinate system

Because Adaptive Distance spatial weight method is distance-based spatial weight method, the data needs to be converted into projected coordinate system. The EPSG code we will convert the data into is [EPSG:26391](https://epsg.io/26391), used for Nigeria West Belt. We will use `st_transform()` from the **sf** package for the task.

```{r}
nga_wp <- st_transform(nga_wp, crs = 26391)
```

#### Computing Adaptive Weight Matrix

As a rule of thumb, when computing adaptive weight matrix, we should ensure that each feature has at least 8 neighbors. To do the task, the functions below are called:

-   [`knn2nb()`](https://www.rdocumentation.org/packages/spdep/versions/1.2-7/topics/knn2nb): converts aÂ **knn**Â object returned byÂ **knearneigh**Â into a neighbors list of classÂ **nb**Â with a list of integer vectors containing neighbor region number ids.

-   [`knearneigh()`](https://r-spatial.github.io/spdep/reference/knearneigh.html): returns a matrix with the indices of points belonging to the set of the k nearest neighbours of each other.

-   [`map_dbl()`](https://purrr.tidyverse.org/reference/map.html): returns an atomic vector of the indicative type.

-   [`st_centroid()`](https://r-spatial.github.io/sf/reference/geos_unary.html): calculates and retrieve the centroid of the feature.

-   [`cbind()`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cbind): merges two data frames/vectors/matrices together

```{r}
#Calculate the longitude and latitude
longitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])
latitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])
coords <- cbind(longitude, latitude)
wp_k8 <- knn2nb(knearneigh(coords, k = 8))
```

Displaying the content of `wp_k8` matrix using `str()`. Each feature has 8 neighbors.

```{r}
str(wp_k8)
```

Now we can plot the adaptive spatial weight matrix.

```{r}
plot(nga_wp$geometry, border = "lightgrey", main = "K Nearest Neighbor Matrix")
plot(wp_k8, coords, pch = 19, cex = 0.2, add = TRUE, col = "red")
```

#### Row standardized weight matrix

We will compute a row standardized weight matrix based on `wp_k8` by using `nb2listw()` from **spdep** package.

```{r}
wp_rsw <- nb2listw(wp_k8, style = "W", zero.policy = TRUE)
wp_rsw
```

### Global Spatial Autocorrelation: Moran's I

#### Moran's I test

To perform the Moran's I test, we will use `moran.test()` from **spdep** package.

```{r}
moran.test(nga_wp$`wpt non-functional`, listw = wp_rsw, zero.policy = TRUE, na.action = na.omit)
```

Because the p-value of the test is less than 0.05, we reject the null hypothesis that the non-functional water points are spatially random at 95% confident interval. As the Moran statistic is 0.383, greater than 0, we can say that the non-functional water point observations are clustered.

#### Monte Carlo Moran's I

To compute 1,000 simulations of Monte Carlo Moran's I, we will use `moran.mc()` from **spdep** package.

```{r}
set.seed(1234)
mc_moran = moran.mc(nga_wp$`wpt non-functional`,
                    listw = wp_rsw,
                    nsim = 999,
                    zero.policy = TRUE,
                    na.action = na.omit)
mc_moran
```

As p-value is 0.001 and less than 0.05, we reject the null hypothesis of spatial randomness among the non-functional water point observations. The statistic of the Moran's I simulations is 0.3831, greater than 0, corroborating the test result that similar non-functional water point observations are clustered.

#### Visualzing Monte Carlo Moran's I

```{r}
summary(mc_moran$res)
```

```{r}
hist(mc_moran$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Moran's I",
     main = "Histogram of Moran's I Simulation")
abline(v = 0, col = "red")
```

We can see that the min of the Moran's I value is less than 0, while the max value is 0.38. The Moran's I data is approaching 1, inferring similar values are clustered. In layman terms, government areas with similar number of non-functional water points tend to be closer together and form some clusters.

### Global Spatial Autocorrelation: Geary's C

The following section will focus on Geary's C test and Geary's C Monte Carlo simulation using the functions from **spdep** package.

#### Geary's C Test

```{r}
geary.test(nga_wp$`wpt non-functional`, listw = wp_rsw)
```

Because p-value is 0.001 and less than 0.05, we reject the null hypothesis of spatial randomness among the non-functional water point observations with 95% confident interval. The statistic of the Geary's C simulations is 0.605, less than 1, we can say that the data tend to cluster among similar observations.

#### Monte Carlo Geary's C

We will compute 1000 simulations of Geary's C using `geary.mc()`.

```{r}
set.seed(1234)
mc_geary = geary.mc(nga_wp$`wpt non-functional`, listw = wp_rsw, nsim = 999)
mc_geary
```

The result of the simulation corroborates the previous Geary's C test with p-value less than 0.05 and Geary's C statistic less than 1.

#### Visualizing Monte Carlo Geary's C

```{r}
summary(mc_geary$res)
```

```{r}
hist(mc_geary$res,
     freq = TRUE,
     breaks = 20,
     main = "Histogram of Geary's C Simulation",
     xlab = "Simulated Geary's C")
abline(v = 1, col = "red")
```

We can see that the min Geary's C is less than 1, while the max is greater than 1. The Geary's C data is approaching 0, meaning similar values are clustered. This result again is similar to Moran's I. We have areas with similar number of non-functional water points clustering together.

## Spatial Correlogram with Moran's I

We will use `sp.correlogram()` from spdep package to compute a 6-lag spatial correlogram of non-functional water points.

```{r}
MI_corr <- sp.correlogram(wp_k8, 
                          nga_wp$`wpt non-functional`, 
                          order=10, 
                          method="I", 
                          style="W")
plot(MI_corr, main = "Moran's I Correlogram of Non-functional Water Points")
```

```{r}
print(MI_corr)
```

The higher the lag value, the lower the estimation of Moran's I value. From lag 8, the values start to be dispersed with Moran's I estimation less than 0. Except for lag 7, we can reject the null hypothesis of spatial randomness for other lag values.
